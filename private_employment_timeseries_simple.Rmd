---
title: "R Notebook"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}

library(dplyr)
library(zoo)
library(lubridate)
library(imputeTS)
library(tidyquant)
library(timetk)
library(broom)
library(ggplot2)
library(prophet)
library(forecast)
library(tidymodels)
library(modeltime)
library(modeltime.ensemble)
library(thief)
library(DataExplorer)
library(tidyverse)
library(data.table)
library(scales)




```


```{r}

#read employment dataset

#https://adpemploymentreport.com/

emp_df <- read.csv("../us-private-employment_1.csv")

emp_df$DateTime <- as.Date(emp_df$DateTime)

emp_df <- emp_df %>%
  mutate(Private.Employment = as.numeric(Private.Employment))

class(emp_df$DateTime)

```


```{r}

#standardize data

df_scaled <- emp_df %>%
  mutate(employ_scale = scale(Private.Employment)) %>%
  mutate(Employment_type = "Private_Employment") %>%
  select(4,1,3)%>%
  rename("ds" = "DateTime", "y" = "employ_scale")

```


```{r}

#make table to save mean and standard deviation

inversion_table <- data.frame(mean_employ = mean(emp_df$Private.Employment),
sd_employ = sd(emp_df$Private.Employment))

```



```{r}

#plot of standardized data

library(ggplot2)


ggplot(df_scaled, aes(x = ds)) +
  geom_line(aes(y = y, color = "Amount"), size = 1.5) +
  xlim(as.Date("2019-01-01"), as.Date("2024-01-01")) +  
  labs(title = "Private Employment 2010 - 2023",
       x = "Datetime",
       y = "Amount") +
  scale_color_manual(values = c("Private.Employment" = "blue")) +
  theme_minimal()

```

```{r}

nested_data_table <- df_scaled %>%
  extend_timeseries(.id_var = Employment_type,
                    .date_var = ds,
                    .length_future = 4) %>%
  nest_timeseries(.id_var = Employment_type,
                  .length_future = 4) %>%
  split_nested_timeseries(.length_test = 6)


extract_nested_train_split(nested_data_table)

```

```{r}

recipe_spec_timeseries <- recipe(y~.,data = extract_nested_train_split(nested_data_table)) %>%
  step_timeseries_signature(ds)

recipe_spec_final <-
  recipe_spec_timeseries %>%
  step_rm(contains("iso"),contains("minute"),contains("hour"),
          contains("am.pm"),contains("xts"),contains("second")) %>%
  step_normalize(contains("index.num")) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE)

bake(prep(recipe_spec_final), extract_nested_train_split(nested_data_table))


```
```{r}

#split data into train and test

train <- df_scaled %>%
    filter(ds < ymd("2023-04-01"))

test <- df_scaled %>%
    filter(ds >= ymd("2023-04-01"))

```



```{r}

#model 1 arima

arima_model <-
  arima_reg() %>%
  set_engine(engine = "auto_arima") %>%
  fit(y ~ ds, data = train)


#model 2 exponential smoothing

es_model <- exp_smoothing() %>%
    set_engine(engine = "ets") %>%
    fit(y ~ ds, data = train)


#model 3 linear regression

lm_spec <-
  linear_reg(mode="regression") %>%
  set_engine("lm")

lm_model <- 
  workflow() %>%
  add_model(lm_spec) %>%
  add_recipe((recipe_spec_final))

#model 4 prophet

prophet_spec <-
  recipe(y~ds,extract_nested_train_split(nested_data_table))

prophet_model <-
  workflow() %>%
  add_model(
    prophet_reg("regression",
                seasonality_weekly = FALSE,
                seasonality_daily = FALSE,
                seasonality_yearly = TRUE) %>%
      set_engine("prophet")
    ) %>%
  add_recipe(prophet_spec)

#model 5 xgboost

xgboost_spec <-
  recipe(y~ds,extract_nested_train_split(nested_data_table)) %>%
  step_timeseries_signature(ds) %>%
  step_rm(ds) %>%
  step_normalize(contains("index.num")) %>%
  step_zv(all_predictors()) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE)

xgboost_model_1 <-
  workflow() %>%
  add_model(boost_tree("regression", learn_rate = 0.35) %>% set_engine("xgboost")) %>%
  add_recipe(xgboost_spec)


xgboost_model_2 <-
  workflow() %>%
  add_model(boost_tree("regression", learn_rate = 0.5) %>% set_engine("xgboost")) %>%
  add_recipe(xgboost_spec)


```


```{r}

parallel_start(6)
set.seed(123)

nested_modeltime_employ_tbl <- nested_data_table %>%
  modeltime_nested_fit(
    model_list = list(
      arima_model,
      es_model,
      lm_model,
      prophet_model,
      xgboost_model_1,
      xgboost_model_2
    ),
    control = control_nested_fit(
      verbose = TRUE,
      allow_par = TRUE
    )
  )
  

#check errors

extract_nested_error_report((nested_modeltime_employ_tbl))

#review test accuracy

rmse_tibble <- nested_modeltime_employ_tbl %>%
  extract_nested_test_accuracy() %>%
  table_modeltime_accuracy(.interactive = TRUE)


#visualize model fits for each subset

nested_modeltime_employ_tbl %>%
  extract_nested_test_forecast() %>%
  group_by(Employment_type) %>%
  plot_modeltime_forecast(.facet_ncol = 2,
                          .legend_max_width = 25,
                          .interactive = "TRUE")

```



```{r}

#forecast future

#fit models

nested_best_refit_cost_table <-
  nested_modeltime_employ_tbl %>%
  modeltime_nested_refit(
    control = control_refit(
      verbose = TRUE,
      allow_par = TRUE
    )
  )

#visualise future forecast of top two models, Linear Regression and Arima

nested_best_refit_cost_table %>%
  extract_nested_future_forecast() %>%
  filter(.model_desc=="ARIMA"|.model_desc=="LM"|.model_desc=="ACTUAL") %>%
  plot_modeltime_forecast(.facet_ncol = 2.,
                          .interactive = TRUE)

#output the forecasting

final_forecast_output <-
  nested_best_refit_cost_table %>%
  extract_nested_future_forecast() %>%
  group_by(Employment_type) %>%
  filter(.model_desc=="ARIMA"|.model_desc=="LM"|.model_desc=="ACTUAL")

final_forecast_output_cleaned <- 
  final_forecast_output[,c(".index","Employment_type",".model_desc",".value")]

final_forecast_output_cleaned <- final_forecast_output_cleaned %>% rename("ds" = ".index",model =".model_desc", "y" = ".value")


```


```{r}

#Arima was chosen as linear regression had a zig zag growth trend, which is not the pattern job growth is usually in.

nested_best_refit_cost_table %>%
  extract_nested_future_forecast() %>%
  filter(.model_desc=="ARIMA"|.model_desc=="ACTUAL") %>%
  plot_modeltime_forecast(.facet_ncol = 2.,
                          .interactive = TRUE)


```

```{r}

arima_forecast <- final_forecast_output_cleaned[final_forecast_output_cleaned$model == "ARIMA" , c("ds", "y")]

#mean of scaled data

emp_mean <- inversion_table$mean_employ
  
emp_sd <- inversion_table$sd_employ

inverted_arima_forecast <- arima_forecast%>% 
  mutate(inverted = (y*emp_sd)+emp_mean)%>% 
  select(1,3)

colnames(inverted_arima_forecast) <- c("DateTime","Private.Employment")

```


```{r}

#Visualize forecast data

#bind actual data with forecast data
final_data <-rbind(emp_df,inverted_arima_forecast)%>%
  mutate(Group = ifelse(DateTime < as.Date("2023-10-01"),"actual","forecast"))%>%
  mutate(pe_pct_change = ((Private.Employment - lag(Private.Employment)) / lag(Private.Employment) )* 100) #make column for percent change of employment numbers

ggplot(final_data, aes(x = DateTime, y = Private.Employment)) +
  geom_line(aes(color = Group)) +
  scale_color_manual(values = c("blue", "red")) +
  xlim(as.Date("2022-01-01"), as.Date("2024-01-01")) +  
  ylim(1.2e+08, 1.4e+08)+
  geom_point() +
  scale_y_continuous(labels = label_number_si())+
  labs(title = "Private Employment Forecast", x = "DateTime", y = "Amount")
  theme_classic()
  
  
ggplot(final_data, aes(x = DateTime, y = pe_pct_change)) +
  geom_line(aes(color = Group)) +
  scale_color_manual(values = c("green", "purple")) +
  ylim(-1, 1) +
  xlim(as.Date("2022-01-01"), as.Date("2024-01-01")) +
  geom_point() +
  scale_y_continuous(labels = label_number_si())+
  labs(title = "Private Employment Forecast", x = "DateTime", y = "Monthly Pct Change")
  theme_classic()


```


```{r}

avg_01 <- mean(final_data$pe_pct_change[final_data$DateTime>=as.Date("2023-01-01")&final_data$DateTime<as.Date("2023-10-01")])


avg_02 <- mean(final_data$pe_pct_change[final_data$DateTime>=as.Date("2023-10-01")])

print(avg_01)

print(avg_02)


```




